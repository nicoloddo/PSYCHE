R. R. Morris, K. Kouddous, R. Kshirsagar, and S. M. Schueller, “Towards an Artificially Empathic Conversational Agent for Mental Health Applications: System Design and User Perceptions,” J Med Internet Res, vol. 20, no. 6, p. e10148, Jun. 2018, doi: 10.2196/10148.
[1] R. Hortensius, F. Hekele, and E. S. Cross, “The Perception of Emotion in Artificial Agents,” IEEE Trans. Cogn. Dev. Syst., vol. 10, no. 4, pp. 852–864, Dec. 2018, doi: 10.1109/TCDS.2018.2826921.
[1] S. Brave, C. Nass, and K. Hutchinson, “Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent,” International Journal of Human-Computer Studies, vol. 62, no. 2, pp. 161–178, Feb. 2005, doi: 10.1016/j.ijhcs.2004.11.002.
[1] H. Abdollahi, M. H. Mahoor, R. Zandie, J. Siewierski, and S. H. Qualls, “Artificial Emotional Intelligence in Socially Assistive Robots for Older Adults: A Pilot Study,” IEEE Trans. Affective Comput., pp. 1–1, 2022, doi: 10.1109/TAFFC.2022.3143803.
[1] A. Paiva et al., “Caring for Agents and Agents that Care: Building Empathic Relations with Synthetic Agents,” Autonomous Agents and Multiagent Systems, International Joint Conference on, vol. 1, pp. 194–201, Jan. 2004, doi: 10.1109/AAMAS.2004.82.
[1] A. A. Salah, A. A. Salah, H. Kaya, M. Doyran, and E. Kavcar, “The sound of silence: Breathing analysis for finding traces of trauma and depression in oral history archives,” Digital Scholarship in the Humanities, vol. 36, no. Supplement_2, pp. ii2–ii8, Nov. 2021, doi: 10.1093/llc/fqaa056.
[1] F. A. Boiten, N. H. Frijda, and C. J. E. Wientjes, “Emotions and respiratory patterns: review and critical analysis,” International Journal of Psychophysiology, vol. 17, no. 2, pp. 103–128, Jul. 1994, doi: 10.1016/0167-8760(94)90027-2.
[1] P. Philippot, G. Chapelle, and S. Blairy, “Respiratory feedback in the generation of emotion,” Cognition & Emotion, vol. 16, no. 5, pp. 605–627, Aug. 2002, doi: 10.1080/02699930143000392.
[1] R. H. Roes, F. Pessanha, and A. Akdag Salah, “An Emotional Respiration Speech Dataset,” Association for Computing Machinery (ACM), Nov. 2022, pp. 70–78. doi: 10.1145/3536220.3558803.
[1] Y. Terzioglu, B. Mutlu, and E. Sahin, “Designing social cues for collaborative robots: The role of gaze and breathing in human-robot collaboration,” in ACM/IEEE International Conference on Human-Robot Interaction, IEEE Computer Society, Mar. 2020, pp. 343–357. doi: 10.1145/3319502.3374829.
[1] T. A. Klausen, U. Farhadi, E. Vlachos, and J. Jorgensen, “Signalling Emotions with a Breathing Soft Robot,” in 2022 IEEE 5th International Conference on Soft Robotics, RoboSoft 2022, Institute of Electrical and Electronics Engineers Inc., 2022, pp. 194–200. doi: 10.1109/RoboSoft54090.2022.9762140.
[1] D. Novick, M. Afravi, and A. Camacho, “Paolachat: A virtual agent with naturalistic breathing,” in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), Springer Verlag, 2018, pp. 351–360. doi: 10.1007/978-3-319-91581-4_26.
[1] U. Bernardet, A. Feng, S. Dipaola, and A. Shapiro, “Speech Breathing in Virtual Humans: An Interactive Model and Empirical Study,” 2019.
[1] Éva Székely, Gustav Eje Henter, Jonas Beskow, and Joakim Gustafson, “Breathing and speech planning in spontaneous speech synthesis,” in ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2020.
